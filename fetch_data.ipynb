{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "import urllib3\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "db_con = sqlite3.connect(\"mydatabase.db\")\n",
    "cursor = db_con.cursor()\n",
    "\n",
    "#cursor.executescript('drop table if exists corpus;')\n",
    "cursor.execute(\"\"\"CREATE TABLE if not exists corpus\n",
    "                  (name text, party text, function text, maintext text) \n",
    "               \"\"\")\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "# API key is curently not needed, but may be in the future?\n",
    "# may register at: http://data.stortinget.no/no/dokumentasjon-og-hjelp/api-nokkel/\n",
    "# if not valid key or empty, gives 'bad request' error\n",
    "API_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first fetch ids of all sessions\n",
    "sesjoner_url = 'http://data.stortinget.no/eksport/sesjoner?key=' + API_key\n",
    "sesjoner_respons = http.request('GET', sesjoner_url)\n",
    "sesjoner_root = et.fromstring(sesjoner_respons.data)\n",
    "\n",
    "sesjoner_liste = sesjoner_root.find('{http://data.stortinget.no}sesjoner_liste')\n",
    "sesjoner = []\n",
    "\n",
    "for sesjon in sesjoner_liste.findall('{http://data.stortinget.no}sesjon'):\n",
    "    sesjoner.append(sesjon.find('{http://data.stortinget.no}id').text)\n",
    "\n",
    "print('Got ' + str(len(sesjoner)) + ' sessions.')\n",
    "\n",
    "# hardcode list of all sessions, based on the above on 2018-03-25, \n",
    "#sesjoner = ['2018-2019',  '2017-2018', '2016-2017', '2015-2016', '2014-2015', '2013-2014', '2012-2013', \n",
    "#         '2011-2012', '2010-2011', '2009-2010', '2008-2009', '2007-2008', '2006-2007', '2005-2006', \n",
    "#         '2004-2005', '2003-2004', '2002-2003', '2001-2002', '2000-2001', '1999-2000', '1998-99', \n",
    "#         '1997-98', '1996-97', '1995-96', '1994-95', '1993-94', '1992-93', '1991-92', '1990-91', \n",
    "#         '1989-90', '1988-89', '1987-88', '1986-87']\n",
    "\n",
    "# publications from http://data.stortinget.no/eksport/ got a new format starting from the 2016-2017, session, therefore save the index off that session:\n",
    "nytt_format_ix = sesjoner.index('2016-2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next fetch all publications\n",
    "# create tw olists to deal with format change\n",
    "publikasjoner = []\n",
    "publikasjoner_eldreformat = []\n",
    "\n",
    "iterasjon = 0\n",
    "for sesjonsid in sesjoner:\n",
    "    print('\\rImport iterasjon ' + str(iterasjon + 1) + ' of ' + str(len(sesjoner)),  end='')\n",
    "    publikasjoner_url = 'http://data.stortinget.no/eksport/publikasjoner?key=' + API_key + '&publikasjontype=referat&sesjonid=' #+ sesjonid\n",
    "    publikasjoner_respons = http.request('GET', publikasjoner_url + sesjonsid)\n",
    "    publikasjoner_root = et.fromstring(publikasjoner_respons.data)\n",
    "\n",
    "    publikasjoner_liste = publikasjoner_root.find('{http://data.stortinget.no}publikasjoner_liste')\n",
    "\n",
    "    for pub in publikasjoner_liste.findall('{http://data.stortinget.no}publikasjon'):\n",
    "        if iterasjon <= nytt_format_ix:\n",
    "            publikasjoner.append(pub.find('{http://data.stortinget.no}id').text)\n",
    "        else:\n",
    "            publikasjoner_eldreformat.append(pub.find('{http://data.stortinget.no}id').text)\n",
    "    iterasjon += 1\n",
    "print('\\rFinished import of '  + str(len(sesjoner)) + ' reference-ids.',  end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch person info to finn in party where missing\n",
    "stortingsperioder = ['2017-2021', '2013-2017', '2009-2013', '2005-2009', '2001-2005', '1997-2001', '1993-97', '1989-93']\n",
    "rep_list = []\n",
    "\n",
    "iterasjon = 0\n",
    "for periode in stortingsperioder:\n",
    "    representanter_url = 'http://data.stortinget.no/eksport/representanter?key=' + API_key + '&stortingsperiodeid=' #+ periodeid\n",
    "    representanter_respons = http.request('GET', representanter_url + periode)\n",
    "    representanter_root = et.fromstring(representanter_respons.data)\n",
    "    \n",
    "    representanter_liste = representanter_root.find('{http://data.stortinget.no}representanter_liste')\n",
    "    for rep in representanter_liste.findall('{http://data.stortinget.no}representant'):\n",
    "        rep_id = rep.find('{http://data.stortinget.no}id').text\n",
    "        rep_for = rep.find('{http://data.stortinget.no}fornavn').text\n",
    "        rep_etter = rep.find('{http://data.stortinget.no}etternavn').text\n",
    "        rep_parti = rep.find('{http://data.stortinget.no}parti')\n",
    "        rep_partiid = rep_parti.find('{http://data.stortinget.no}id').text\n",
    "        rep_partinavn = rep_parti.find('{http://data.stortinget.no}navn').text\n",
    "        rep_row = [rep_id, rep_for + ' ' + rep_etter, rep_partiid, rep_partinavn, stortingsperioder[iterasjon]]\n",
    "        rep_list.append(rep_row)\n",
    "    iterasjon += 1\n",
    "\n",
    "columns = ['id', 'navn', 'partiid', 'partinavn', 'stortingsperiode']\n",
    "representanter_ses = pd.DataFrame(rep_list, columns=columns)\n",
    "\n",
    "# add some members of government who have not been in parlament\n",
    "representanter_legges_til = [\n",
    "    [\"VidHel\", \"Vidar Helgesen\", \"H\", \"Høyre\", \"\"],\n",
    "    ['MonMae', 'Monica Mæland', 'H', 'Høyre', ''],\n",
    "    ['AnnHau', 'Anniken Hauglie', 'H', 'Høyre', ''],\n",
    "    ['MarBer', 'Marit Berger Røsland', 'H', 'Høyre', ''],\n",
    "    ['TerSoe', 'Terje Søviknes', 'FrP', 'Fremskrittspartiet', '']\n",
    "]\n",
    "\n",
    "# adds above list til dataframe\n",
    "for li in representanter_legges_til:\n",
    "    representanter_ses.loc[len(representanter_ses)] = li\n",
    "\n",
    "# group by id to remove some duplicates\n",
    "representanter = representanter_ses.groupby(['id']).first().reset_index().set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions for cleaning strings and fetching party from representanter-dataframe\n",
    "\n",
    "funksjoner =[\"Statsminister\", \"Statsråd\", \"Utenriksminister\", \"Stortingspresident\"]\n",
    "\n",
    "def move_function_from_name(string):\n",
    "    # subfunction of clean_representant_string()\n",
    "    # take string, return list with name[0], function[1]\n",
    "    navn = string\n",
    "    funksjon = ''\n",
    "    string_words = string.split()\n",
    "    if (len(string_words) > 0) and (string_words[0] in funksjoner):\n",
    "        navn = ' '.join(string_words[1:])\n",
    "        funksjon = string_words[0]\n",
    "    return [navn, funksjon]\n",
    "\n",
    "def clean_representant_string(string):\n",
    "    # take string found in newer http://data.stortinget.no/eksport/publikasjon?publikasjonid\n",
    "    # return list with name [0] and party [1], elective_function[2]\n",
    "    \n",
    "    rep_navn = re.search(r\"^[^\\(|^\\[]*\", string)\n",
    "    if rep_navn: \n",
    "        # lots of noise in xml files which complicated party lookup\n",
    "        rep_navn = rep_navn.group(0).strip()\n",
    "        rep_navn = rep_navn.replace('\\n', ' ')\n",
    "        rep_navn = rep_navn.replace('\\xad', '')\n",
    "        rep_navn = rep_navn.strip(':')\n",
    "    else:\n",
    "        rep_navn = \"unknown\"\n",
    "    \n",
    "    rep_navn, rep_funksjon = move_function_from_name(rep_navn)\n",
    "    \n",
    "    # fetch party from string in xml inside ()\n",
    "    rep_parti = re.search(r\"\\(([A-Za-z0-9_]+)\\)\", string)\n",
    "    if rep_parti: \n",
    "        rep_parti = rep_parti.group(1)\n",
    "    else:\n",
    "        # else fetch party from representanter-dataframe\n",
    "        if not representanter.loc[representanter.navn == rep_navn.strip(), 'partiid'].empty:\n",
    "            rep_parti = representanter.loc[representanter.navn == rep_navn.strip(), 'partiid'][0]\n",
    "        else:\n",
    "            rep_parti = \"unknown\"\n",
    "    \n",
    "    return([rep_navn, rep_parti, rep_funksjon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by 2018-03-25 there is about 180 documents with new format (about 34 MB in sqlite database)\n",
    "# and ~1622 with old format (this plus the above is about 268 MB in sqlite database)\n",
    "\n",
    "# new foramt id-s stored in list: publikasjoner\n",
    "# old foramt id-s stored in list: publikasjoner_eldreformat\n",
    "\n",
    "# first fetch the new format docs, and store in sqlite database, table 'corpus'\n",
    "\n",
    "#ref_liste = [] # for testing\n",
    "ref_rad = []\n",
    "\n",
    "referat_juks = [publikasjoner[75]]\n",
    "iterasjon = 0\n",
    "for referat in publikasjoner: # publikasjoner eller referat_juks for test\n",
    "    print('\\rImport referat ' + str(iterasjon + 1) + ' av ' + str(len(publikasjoner)),  end='')\n",
    "    iterasjon += 1\n",
    "\n",
    "    referat_url = 'http://data.stortinget.no/eksport/publikasjon?key=' + API_key + '&publikasjonid='\n",
    "    referat_respons = http.request('GET', referat_url + referat) # referat\n",
    "    referat_root = et.fromstring(referat_respons.data)\n",
    "    referat_mote = referat_root.find('Mote')\n",
    "    if referat_mote is not None:\n",
    "        referat_hoved = referat_mote.find('Hovedseksjon')\n",
    "    else: \n",
    "        print('\\nSkipping ' + referat)\n",
    "        continue\n",
    "        \n",
    "    if referat_hoved is not None:\n",
    "        referat_saker = referat_hoved.find('Saker') # breaks on 35\n",
    "    else:\n",
    "        print('\\nSkipping ' + referat)\n",
    "        continue\n",
    "\n",
    "    for sak in referat_saker.findall('*'):\n",
    "        for hoved in sak.findall('Hovedinnlegg'):\n",
    "            for all_as in hoved.findall('A'):\n",
    "                navn = all_as.find('Navn')\n",
    "                if navn is not None: \n",
    "                    if len(ref_rad) > 0: \n",
    "                        #ref_liste.append(ref_rad) # for test\n",
    "                        cursor.execute('''INSERT INTO corpus(name, party, function, maintext) VALUES(?,?,?,?)''', (r_navn, r_parti, r_funksjon, ref_rad[-1]))\n",
    "                    ref_rad = []\n",
    "                    if navn.text is not None:\n",
    "                        r_navn, r_parti, r_funksjon = clean_representant_string(navn.text)\n",
    "                        ref_rad.append(r_navn)\n",
    "                        ref_rad.append(r_parti)\n",
    "                        ref_rad.append(r_funksjon)\n",
    "                    if navn.tail is not None:\n",
    "                        ref_rad.append(navn.tail.replace('\\n', ' ').replace(u'\\xa0', u' ').strip())\n",
    "                    #print(ref_rad) # test stuff\n",
    "                ref_rad[-1] = ref_rad[-1] + str(all_as.text).replace('\\n', ' ').replace(u'\\xa0', u' ').strip()\n",
    "    cursor.execute('''INSERT INTO corpus(name, party, function, maintext) VALUES(?,?,?,?)''', (r_navn, r_parti, r_funksjon, ref_rad[-1]))\n",
    "    db_con.commit()\n",
    "            \n",
    "#len(ref_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to fetch documents with old format, with id-s from 'publikasjoner_eldreformat'\n",
    "\n",
    "ref_liste = []\n",
    "ref_rad = []\n",
    "parse_errors = []\n",
    "\n",
    "referat_test = [publikasjoner_eldreformat[1205]]\n",
    "iterasjon = 0\n",
    "for referat in publikasjoner_eldreformat: # publikasjoner_eldreformat eller referat_test for test\n",
    "    print('\\rImport referat ' + str(iterasjon + 1) + ' av ' + str(len(publikasjoner_eldreformat)),  end='')\n",
    "    iterasjon += 1\n",
    "\n",
    "    referat_url = 'http://data.stortinget.no/eksport/publikasjon?key=' + API_key + '&publikasjonid='\n",
    "    referat_respons = http.request('GET', referat_url + referat) # referat\n",
    "    # some cheking of valid xml? last 27 in list not valid\n",
    "    try:\n",
    "        referat_root = et.fromstring(referat_respons.data) # legge til error handling pga format\n",
    "    except:\n",
    "        parse_errors.append(referat)\n",
    "        continue\n",
    "    \n",
    "    referat_mote = referat_root.find('mote')\n",
    "\n",
    "    if referat_mote is None:\n",
    "        print('skipping' + referat)\n",
    "        continue\n",
    "    else:\n",
    "        referat_innlegg = referat_mote.findall('./saker/sak/innlegg') #navn,a,a,a..\n",
    "        referat_innlegg = referat_innlegg + referat_mote.findall('./saker/sakreferat/referat/innlegg') #navn,a,a,a..\n",
    "    \n",
    "    # en eller annen funksjon som høster navn og alle a-er\n",
    "\n",
    "    for innlegg in referat_innlegg:\n",
    "        # new innlegg\n",
    "        r_innlegg = ''\n",
    "        \n",
    "        navn = innlegg.find('navn')\n",
    "        if (navn is not None) and (navn.text is not None):\n",
    "            r_navn, r_parti, r_funksjon = clean_representant_string(navn.text)\n",
    "        for all_as in innlegg.findall('a'):\n",
    "            # append all the a-s in variable: r_innlegg\n",
    "            r_innlegg = r_innlegg + str(all_as.text).replace('\\n', ' ').replace('                   ', ' ').replace(u'\\xa0', u' ').strip()\n",
    "        \n",
    "        #print('\\n' + r_navn, r_parti, r_funksjon + '\\n' + r_innlegg) # test stuff\n",
    "        #print(r_navn, r_parti) # test stuff\n",
    "        #print(repr(r_navn)) # test stuff for those hidden/strange characters\n",
    "        \n",
    "        # add to db for each speech by person\n",
    "        cursor.execute('''INSERT INTO corpus(name, party, function, maintext) VALUES(?,?,?,?)''', (r_navn, r_parti, r_funksjon, r_innlegg))\n",
    "    \n",
    "    # commit to db for each document\n",
    "    db_con.commit()\n",
    "\n",
    "# a lot of documents in old format couldnt be parsed, so print this number at the end\n",
    "# dident try find workaroudn of these errors\n",
    "print('\\n' + str(len(parse_errors)) + ' errors parsing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write references which gave parse errors to a file \n",
    "thefile = open('parse_errors.txt', 'w')\n",
    "\n",
    "for item in parse_errors:\n",
    "  thefile.write(\"%s\\n\" % item)\n",
    "\n",
    "thefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing if i need to add more representatives\n",
    "# a lot of these are from invited speakers, or nonspecific names\n",
    "# but there are also a lot who are connected to a party\n",
    "# this can definetely be improved upon\n",
    "sql = \"SELECT name FROM corpus WHERE party=?\" #  limit 100\n",
    "cursor.execute(sql, [(\"unknown\")]) # now renamed this ukjent\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
